{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/joh06288/AMIA2019_W07/blob/master/AMIA2019_W07_Modeling_Techniques.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2j08gpeKMo-S"
   },
   "source": [
    "# Model Development & Evaluation\n",
    "\n",
    "## Medinfo 2019\n",
    "### Data Science Workshop\n",
    "#### August 26, 2019\n",
    "\n",
    "### Content Development: Steve Johnson, Lisiane Pruinelli, Alvin Jeffery, Tamara Winden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cpoyAvqLMo-U"
   },
   "source": [
    "**Objectives:**  \n",
    "1. Describe at least 3 modeling/machine learning techniques used in biomedical data science.  \n",
    "2. Develop a machine learning model for predicting a healthcare outcome.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VABepFILMo-V"
   },
   "source": [
    "### 6.1 What is Machine Learning (ML)?\n",
    "\n",
    "Machine Learning (ML) is about coding programs that automatically adjust their performance from exposure to information encoded in data. This learning is achieved via **tunable parameters** that are automatically adjusted according to performance criteria.\n",
    "\n",
    "Machine Learning can be considered a subfield of Artificial Intelligence (AI).\n",
    "\n",
    "There are three major classes of ML:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pEWGPVufMo-W"
   },
   "source": [
    "**Supervised learning**: Algorithms which learn from a training set of *labeled* examples (exemplars) to generalize to the set of all possible inputs.  \n",
    "Examples: regression, support vector machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-ievHo6uMo-X"
   },
   "source": [
    "**Unsupervised learning**: Algorithms which learn from a training set of *unlableled* examples, using the features of the inputs to categorize inputs together according to some statistical criteria.  \n",
    "Examples: k-means clustering, kernel density estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GI2HeYNtMo-X"
   },
   "source": [
    "**Reinforcement learning**: Algorithms that learn via reinforcement from a *critic* that provides information on the quality of a solution, but not on how to improve it. Improved solutions are achieved by iteratively exploring the solution space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "__tm8tnzMo-Y"
   },
   "source": [
    "### 6.2 Introduction to `Scikit-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1ah86-q3Mo-Z"
   },
   "source": [
    "The `scikit-learn` package is an open-source library that provides a robust set of machine learning algorithms for Python. It is built upon the core Python scientific stack (*i.e.* NumPy, SciPy, Cython), and has a simple, consistent interface, making it useful for many data science applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oGDeXNAzMo-a"
   },
   "source": [
    "<img src=\"http://1.bp.blogspot.com/-ME24ePzpzIM/UQLWTwurfXI/AAAAAAAAANw/W3EETIroA80/s1600/drop_shadows_background.png\" width=\"90%\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "LuP1RWUXMo-b",
    "outputId": "e23f9000-6da9-4b7f-df41-b06ad2856896"
   },
   "outputs": [],
   "source": [
    "# previously loaded modules \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mplot\n",
    "%matplotlib inline\n",
    "import IPython\n",
    "from IPython.core.display import HTML\n",
    "from IPython.core.debugger import set_trace\n",
    "from distutils.version import StrictVersion\n",
    "import xlrd \n",
    "print(\"numpy version:  %s\" % np.__version__)\n",
    "print(\"pandas version:  %s\" % pd.__version__)\n",
    "print(\"matplotlib version:  %s\" % mplot.__version__)\n",
    "print(\"IPython version:  %s\" % IPython.__version__)\n",
    "print(\"seaborn version:  %s\" % sns.__version__)\n",
    "\n",
    "if StrictVersion(np.__version__) >= StrictVersion('1.13.0') and \\\n",
    "   StrictVersion(pd.__version__) >= StrictVersion('0.20.0') and \\\n",
    "   StrictVersion(mplot.__version__) >= StrictVersion('2.0.0') and \\\n",
    "   StrictVersion(IPython.__version__) >= StrictVersion('5.5.0') and \\\n",
    "   StrictVersion(sns.__version__) >= StrictVersion('0.7.0'):\n",
    "    print('\\nCongratulations, your environment is setup correctly!')\n",
    "else:\n",
    "    print('\\nEnvironment is NOT setup correctly!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C0y-UdW7Mo-d"
   },
   "outputs": [],
   "source": [
    "# load scikit-learn modules\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random as rnd\n",
    "from random import random, randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FxgQ842dMo-f"
   },
   "source": [
    "### 6.3 Representing Data in `scikit-learn`\n",
    "\n",
    "Most machine learning algorithms implemented in scikit-learn expect data to be stored in a\n",
    "**two-dimensional array or matrix**.  The arrays can be\n",
    "either ``numpy`` arrays, or in some cases ``scipy.sparse`` matrices.\n",
    "The size of the array is expected to be `[n_samples, n_features]`\n",
    "\n",
    "- **n_samples:**   The number of samples: each sample is an item to process (e.g. classify).\n",
    "  A sample can be a document, a picture, a sound, a video, an astronomical object,\n",
    "  a row in database or CSV file,\n",
    "  or whatever you can describe with a fixed set of quantitative traits.\n",
    "- **n_features:**  The number of features or distinct traits that can be used to describe each\n",
    "  item in a quantitative manner.  Features are generally real-valued, but may be boolean or\n",
    "  discrete-valued in some cases.\n",
    "\n",
    "The number of features must be fixed in advance. However it can be very high dimensional\n",
    "(e.g. millions of features) with most of them being zeros for a given sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ytqQyNnRMo-g",
    "outputId": "08d292bd-9611-422b-f469-664a68993941"
   },
   "outputs": [],
   "source": [
    "# load data created from previous steps\n",
    "import os, shutil\n",
    "cwd = os.getcwd()\n",
    "datadir = cwd + '/data_oh'\n",
    "\n",
    "print('Data directory is: {}'.format(datadir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "colab_type": "code",
    "id": "mZ-Efw4iQWvW",
    "outputId": "80c824f8-92c5-4f54-e575-77dd3546e958"
   },
   "outputs": [],
   "source": [
    "# See if the data exists.  If not, try to download it from github.\n",
    "if not os.path.exists(datadir+'/patients.csv'):\n",
    "    print(\"Data directory doesn't exist!\")\n",
    "    print(\"Checking out the data from github...\")\n",
    "\n",
    "    !git clone https://github.com/joh06288/Medinfo2019.git\n",
    "        \n",
    "    # Move the checked-out files into the /data directory\n",
    "    files = os.listdir('Medinfo2019')\n",
    "    for f in files:\n",
    "        print('Moving %s...' % (f,))\n",
    "        try:\n",
    "            shutil.move('Medinfo2019/'+f,'.')\n",
    "        except:\n",
    "            print(\"    Unable to move %s\" % (f,))\n",
    "            \n",
    "    try:\n",
    "        shutil.rmtree('Medinfo2019')  # Remove the version control (git) information\n",
    "    except:\n",
    "        pass  # Ignore errors.  On Windows, this sometimes fails and leaves the .git directory\n",
    "print('Data directory contains:\\n',os.listdir(datadir))\n",
    "\n",
    "df = pd.read_pickle(datadir + '/data_cleaned_oh.pkl')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PDt2rmVGMo-k"
   },
   "source": [
    "### 6.4 Encoding Categorical Variables\n",
    "Most of the models in scikit-learn require the categorical variables be turned into numeric variables.  There are two approaches to this:\n",
    "1. One Hot Encoding - each item in the categorical variable is turned into its own variable represetnting the presence or abscence of that item.  For example, 'Gender' would turn into 2 variables:  'Gender_M' and 'Gender_F'\n",
    "2. Label Encoding - assign an integer to each item.  For the 'Gender' variable, 0 might mean Male and 1 might mean Female.\n",
    "\n",
    "We will use the `LabelEncoder` transformation to change categorical variables into integers.  As a convenience, we can also keep the original (human readable) variable in the Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "colab_type": "code",
    "id": "B1Bv9s6EMo-l",
    "outputId": "c02c295b-d94d-4d8e-a2dc-750816e2876d"
   },
   "outputs": [],
   "source": [
    "# Let's use the following variables as our initial set of predictors\n",
    "cat_cols = ['gender', 'marital', 'race', 'ethnicity']\n",
    "cat_cols_encoded = [c + '_encoded' for c in cat_cols]\n",
    "numeric_cols = ['prior_opioid_abuse_diag', 'age', 'opioid_discharge_days_supply']\n",
    "pred_cols = numeric_cols + cat_cols_encoded\n",
    "target_col = 'overdose'\n",
    "all_cols = cat_cols+numeric_cols+[target_col]\n",
    "\n",
    "df_opioids = df[df['prescribed_opioids'] == 1]\n",
    "\n",
    "# Encode the categorical variables\n",
    "dfe = df_opioids[cat_cols]\n",
    "\n",
    "# Replace missing data with an 'Unknown' category \n",
    "# so the missing data will also be encoded\n",
    "dfe = dfe.replace(np.NaN,'Unknown')\n",
    "\n",
    "# Encode the categorical variables\n",
    "encoded = dfe.apply(preprocessing.LabelEncoder().fit_transform)\n",
    "\n",
    "# Append the non-categorical variables and the encoded variables \n",
    "# into a single Dataframe\n",
    "# Name the new variables as <name>_encoded\n",
    "dfe = pd.concat([df_opioids[all_cols], encoded.add_suffix('_encoded')],axis=1)\n",
    "display(dfe.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "5-eoWlxsMo-o",
    "outputId": "01328f91-bcc8-41f7-806e-00978ec35cc4"
   },
   "outputs": [],
   "source": [
    "# let's build a model using this set of variables...\n",
    "pred_cols = ['age', 'opioid_discharge_days_supply', \n",
    "             'prior_opioid_abuse_diag', \\\n",
    "             'gender_encoded', 'marital_encoded', 'race_encoded', \\\n",
    "             'ethnicity_encoded']\n",
    "#pred_cols = ['prior_abuse_diag', 'adult', 'age_at_visit', \\\n",
    "#             'opioid_discharge_days_supply', 'gender_encoded', \\\n",
    "#             'marital_encoded', 'race_encoded', 'ethnicity_encoded']\n",
    "\n",
    "LR_pred_cols = pred_cols\n",
    "X = dfe[pred_cols].to_numpy()\n",
    "y = dfe['overdose'].to_numpy()\n",
    "print('Using predictor variables of:',pred_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AtH2jwG3Mo-q"
   },
   "source": [
    "### 6.5 How do we approach problems from a Data Science perspective?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dAwy3tikMo-r"
   },
   "source": [
    "Imagine a set of observational (empirical data) that we want to *learn* from...  \n",
    "<img src=\"https://www.learnopencv.com/wp-content/uploads/2017/02/data-points.png\", width='60%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gi6ubxEOMo-s"
   },
   "source": [
    "We can fit a variety of models ranging from extremely *simple* to highly *complex* models, e.g., \n",
    "<img src='https://www.learnopencv.com/wp-content/uploads/2017/02/bias-variance-tradeoff.png' width='60%'/>\n",
    "\n",
    "**What are potential problems with each of these cases?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XTgL2RbAMo-s"
   },
   "source": [
    "When applying these same models to a *new* set of data we held out for testing...\n",
    "<img src='https://www.learnopencv.com/wp-content/uploads/2017/02/bias-variance-tradeoff-test-error.png' width='60%'/>\n",
    "**We were overfit with the more complex, polynomial model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9RCCw-vCMo-t"
   },
   "source": [
    "### Bias vs. Variance\n",
    "<img src='https://www.learnopencv.com/wp-content/uploads/2017/02/Bias-Variance-Tradeoff-In-Machine-Learning-1.png' width='50%'/>\n",
    "\n",
    "**Rule of Thumb:** Fit model complexity to the data resources (not the target complexity)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OiRw6_hPMo-u"
   },
   "source": [
    "### 6.6 Practical Approaches  \n",
    "In Data Science, we tend to do the following with a data set:  \n",
    "1. Learn a model based on training data (e.g., 60% of data)  \n",
    "2. Iteratively modify model based on a validation set:  \n",
    "    2a. Cross-validation/bootstrap with the training data  \n",
    "    2b. Separate validation set (e.g., 20% of data)  \n",
    "3. Estimate generalization error with a test set (e.g., 20% of data) that you only look at once  \n",
    "\n",
    "*Food for Thought:* With small validation sets, error measure is a bad estimator of the best hypothesis.  With large validation sets, error measure is a great estimator of a terrible hypothesis.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DtTuekGYMo-v"
   },
   "source": [
    "### 6.7 Let's Build Some Models!\n",
    "\n",
    "Let's begin preparing our pain data for machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2zA520wWMo-w"
   },
   "source": [
    "### How do these models work?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1n8uM4kRMo-x"
   },
   "source": [
    "#### Logistic Regression\n",
    "<img src='http://www.saedsayad.com/images/LogReg_1.png' width='80%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "spVySm42Mo-y"
   },
   "source": [
    "#### Linear Discriminant Analysis\n",
    "<img src='http://sebastianraschka.com/images/blog/2014/linear-discriminant-analysis/lda_1.png' width='80%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ZWD2aVUMo-z"
   },
   "source": [
    "#### K-Nearest Neighbors\n",
    "<img src='https://upload.wikimedia.org/wikipedia/commons/thumb/e/e7/KnnClassification.svg/220px-KnnClassification.svg.png' width='30%'/>\n",
    "The test sample (green circle) should be classified either to the first class of blue squares or to the second class of red triangles. If k = 3 (solid line circle) it is assigned to the second class because there are 2 triangles and only 1 square inside the inner circle. If k = 5 (dashed line circle) it is assigned to the first class (3 squares vs. 2 triangles inside the outer circle)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F5-leWiCMo-0"
   },
   "source": [
    "#### Decision Trees\n",
    "<img src='https://qph.fs.quoracdn.net/main-qimg-b17755d2e0ffb326d8c39b7f3e07e03b-c' width='80%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7CBThVlLMo-1"
   },
   "source": [
    "#### Random Forest\n",
    "<img src='https://i.ytimg.com/vi/ajTc5y3OqSQ/hqdefault.jpg' width='65%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JpRQg-9RMo-3"
   },
   "source": [
    "#### Gaussian Naive Bayes\n",
    "<img src='https://chrisalbon.com/images/machine_learning_flashcards/Gaussian_Naive_Bayes_Classifier_print.png' width='80%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_uhULC42Mo-4"
   },
   "source": [
    "### 6.8 Let's (Really) Build Some Models! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nUYOO14UMo-5"
   },
   "outputs": [],
   "source": [
    "# models we'll consider\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "colab_type": "code",
    "id": "1VXZNYRyMo-8",
    "outputId": "14255df9-c07f-4943-f319-04e63376ce85"
   },
   "outputs": [],
   "source": [
    "# Let's try a simple logistic regression model to see how predictive our data is\n",
    "\n",
    "# perform a model fit on the training set\n",
    "LR = LogisticRegression()\n",
    "result = LR.fit(X, y)\n",
    "\n",
    "# calculate predicted values from the model to compare with actual outcomes\n",
    "expected = y\n",
    "predicted = LR.predict(X)\n",
    "\n",
    "print('\\nClassification Report\\n',metrics.classification_report(expected, predicted))\n",
    "print('\\nConfusion Matrix\\n',metrics.confusion_matrix(expected, predicted))\n",
    "print('\\nAccuracy score =',metrics.accuracy_score(expected, predicted))\n",
    "print('\\nAUC score =',metrics.roc_auc_score(expected, predicted))\n",
    "print('\\nf1 score =',metrics.f1_score(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P3h5WuRCMo-_"
   },
   "source": [
    "### What do these numbers mean?  \n",
    "According to Wikipedia:\n",
    "\n",
    "![Confusion Matrix](https://github.com/joh06288/AMIA2019_W07/blob/master/images/Sensitivity-Wikipedia.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S4stkwq7Mo_A"
   },
   "source": [
    "Precision = $\\frac{tp}{tp + fp}$ ,  \n",
    "where $tp$ is the number of true positives and $fp$ the number of false positives. The precision is intuitively the ability of the classifier to not label a sample as positive if it is negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sSBxe3JEMo_B"
   },
   "source": [
    "Recall = $\\frac{tp}{tp + fn}$  \n",
    "The recall is intuitively the ability of the classifier to find all the positive samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UVMSLHJ6Mo_C"
   },
   "source": [
    "Accuracy = $\\frac{tp + tn}{N}$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ds7tWSs_Mo_C"
   },
   "source": [
    "$F1 = 2 * \\frac{precision * recall}{precision + recall}$  \n",
    "The $F1$ score can be interpreted as a weighted average of the precision and recall, where an $F1$ score reaches its best value at 1 and worst score at 0. The relative contribution of precision and recall to the $F1$ score are equal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gf0yVePSMo_D"
   },
   "source": [
    "The support is the number of occurrences of each class in $y_{test}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "colab_type": "code",
    "id": "5-cf1gm2Mo_E",
    "outputId": "6d7cc9ba-f6a0-4925-8e61-9947689eb346"
   },
   "outputs": [],
   "source": [
    "# Lets graph an ROC curve for the model\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# we'll use the test set (rather than training) for this evaluation\n",
    "auc = roc_auc_score(y, LR.predict(X))\n",
    "probs = LR.predict_proba(X)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y, probs)\n",
    "tpr[1] = tpr[0]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Model')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ul-XZ5hlMo_G"
   },
   "source": [
    "# 7.0 Model Performance and Evaluation\n",
    "\n",
    "### Goals of Performance Evaluation\n",
    "\n",
    "* To determine the most accurate predictive model\n",
    "\n",
    "* To determine generalizability of the model\n",
    "\n",
    "* To prevent overlearning\n",
    "\n",
    "* To quantify the performance of a model and how we can improve it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6fwF4WlrMo_H"
   },
   "source": [
    "## Cost of Unreliable Predictive Models\n",
    "\n",
    "- Patient Safety and Risk\n",
    "\n",
    "- Poorer Quality and Patient Outcomes\n",
    "\n",
    "- Time Waste (development and application)\n",
    "\n",
    "- Financial \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O5ku01IFMo_I"
   },
   "source": [
    "## Problems to Mitigate\n",
    "\n",
    "The model development process must strike a balance between learning too much and learning too little\n",
    "\n",
    "* Overlearning\n",
    "    * It's quite easy to create a model the \"memorizes\" the data\n",
    "    * It perfectly fits your training data, but is useless when shown new data\n",
    "    * The number of possible ways to train a model is exponential\n",
    "    * Model parameters are too specific to training data\n",
    "* Insufficient training data\n",
    "* Inadequate data set aside for testing and cross-validation\n",
    "* Application of improper model (e.g., linear model on variables with non-linear relationships).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vEEGEPobMo_J"
   },
   "source": [
    "## Dataset Partitioning\n",
    "\n",
    "Experimental validation using an external data set is the best method of validating a model and ensuring generalizability.\n",
    "\n",
    "* Training Dataset - used to build the model via a learning algorithm and to identify discriminating features of the predictor variables \n",
    "\n",
    "* Test Dataset - used to assess the prediction error of the final model\n",
    "\n",
    "* Validation Dataset - used to assess how well the model perform against real data, to ensure stability and, in some cases, to fine-tune the model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bQpju4TtMo_J"
   },
   "source": [
    "## Evaluating Performance\n",
    "\n",
    "* It’s impossible to design a learning method that’s guaranteed not to overlearn¹.\n",
    "* Hold aside some data to test the model (20-30%)\n",
    "* The remaining portion of data (training set) will be used to create the model.\n",
    "* Use a model evaluation metric to compare the performance of predictive models\n",
    "    * Metrics include f-statistic, Lift, Area Under the ROC Curve (AUC), etc.\n",
    "\n",
    "<sub>¹Siegel, E (2016). Predictive Analytics: the power to predict who will click, buy, lie or die. Wiley</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r6G20UBdMo_L"
   },
   "source": [
    "### 7.1 Preventing Overfitting\n",
    "\n",
    "- One way to prevent overfitting is to set aside some portion of the data to test with the model.  Thus the data is split into Training and Test partitions.\n",
    "\n",
    "- We can build a Logistic Regression model that is predictive of overdose risk. But we trained the model and tested it with our entire data set, which isn't exactly a fair test of the model.\n",
    "\n",
    "- We should split our dataset into a training dataset and a test dataset. After we train the model using just the training dataset, we will evaluate the model using the test dataset which has data that the model has never seen before.\n",
    "\n",
    "- `scikit-learn` has a helpful function called train_test_split that randomly splits our dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "q_opJjvjMo_L",
    "outputId": "097d1020-a8db-4a18-9f0d-4e211086e7eb"
   },
   "outputs": [],
   "source": [
    "# Create the training and test datasets\n",
    "# Partition 30% of the data to the Test set\n",
    "train, test = train_test_split(dfe, test_size=0.3, random_state=987)\n",
    "\n",
    "X_train = train[pred_cols].to_numpy()\n",
    "y_train = train['overdose'].to_numpy()\n",
    "X_test = test[pred_cols].to_numpy()\n",
    "y_test = test['overdose'].to_numpy()\n",
    "\n",
    "print('X_train shape = ',X_train.shape)\n",
    "print('y_train shape = ',y_train.shape)\n",
    "print('X_test shape = ',X_test.shape)\n",
    "print('y_test shape = ',y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ms2lg07dMo_Q"
   },
   "source": [
    "### 7.2 Training and Test Errors\n",
    "\n",
    "- Training Error: calculated by applying the statistical learning method to the observations used in the training.\n",
    "\n",
    "- Test Error: the average error that results from using a statistical learning method to predict the response on a new observation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j0RdbttoMo_Q"
   },
   "source": [
    "## Training vs Test Performance\n",
    "\n",
    "The validation estimate of the test error can be highly variable, depending on precisely which observations are included in the training set and which observations are included in the validation set.\n",
    "\n",
    "<img src='https://github.com/joh06288/AMIA2019_W07/blob/master/images/TrainingTestPerformance.png?raw=1' width='70%'>\n",
    "\n",
    "<sub>¹Cross-validation and bootstrap. Stanford Lagunita. Humanities Science. Statistical Learning.</sub>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wpGUQ2H3Mo_R"
   },
   "source": [
    "### 7.3 Example: Evaluating Performance of a Decision Tree\n",
    "\n",
    "There is always a tension (tug-of-war) between learning and overlearning. The recommended approach is to overlearn and then cut-back on the tree.\n",
    "\n",
    "Let's create a decision tree that overlearns the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O2iGg_CsMo_S"
   },
   "outputs": [],
   "source": [
    "# Create Decision Tree models with tree depths of 1 to 25\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "tree_depths = np.linspace(1, 25, 25, endpoint=True)\n",
    "train_auc = []\n",
    "test_auc = []\n",
    "for d in tree_depths:\n",
    "    dt = DecisionTreeClassifier(max_depth=d)\n",
    "    dt.fit(X_train, y_train)  # Fit a model to a tree at the current tree depth\n",
    "    # Calc the false positive rate and the true positive rates by comparing the training answers to the model\n",
    "    pred = dt.predict(X_train)\n",
    "    # Compute the AUC from the rates and append it to the training auc data\n",
    "    fpr, tpr, thresholds = roc_curve(y_train, pred)\n",
    "    train_auc.append(auc(fpr, tpr))\n",
    "    # Calc the false positive rate and the true positive rates by comparing the test answers to the model\n",
    "    pred = dt.predict(X_test)\n",
    "    # Compute the AUC from the rates and append it to the test auc data\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, pred)\n",
    "    test_auc.append(auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "colab_type": "code",
    "id": "38CtlBFSMo_W",
    "outputId": "ba24ceee-2201-414f-d737-4f63c44a44a5"
   },
   "outputs": [],
   "source": [
    "# Graph the AUCs of the training and test models at various tree depths\n",
    "# Notice that the training scores continue to improve until they hit 1.0 (Perfect model, complete memorization)\n",
    "# But the test scores get worse as the training model improves\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(tree_depths, train_auc, 'g', label='Train AUC')\n",
    "plt.plot(tree_depths, test_auc, 'r', label='Test AUC')\n",
    "plt.legend(loc=3)\n",
    "plt.ylim((0.5,1.01))\n",
    "plt.ylabel('AUC')\n",
    "plt.xlabel('Tree Depth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y1Qcw3YXMo_Z"
   },
   "source": [
    "### 7.4 Resampling Methods\n",
    "\n",
    "Splitting the data into a training dataset and a test dataset has a drawback in that it doesn't allow us to train the model on all of the data.  \n",
    "\n",
    "Two common resampling methods are k-fold cross-validation and bootstrap\n",
    "\n",
    "- Involve repeated drawing samples from a training set and refitting a model of interest on each sample in order to obtain additional information about the fitted model and use all of the data for training while preventing overfitting\n",
    "\n",
    "- Provide estimates for test-set prediction error, standard deviation and bias of parameter estimates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Epgpyp7Mo_Z"
   },
   "source": [
    "### 7.41 K-fold Cross Validation\n",
    "\n",
    "- K-fold cross validation randomly divides the data into k equal sized subsets and then trains the model on the remaining k-1 segments of the data and tests it on the data that was held out.  \n",
    "- The process is repeated k times so that in the end all of the data is used at some point to train the model.  \n",
    "- The k model results are averaged to produce a single estimate of model performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L5B3rjhLMo_a"
   },
   "source": [
    "## K-fold Cross Validation\n",
    "<img src=images/kfold.png width='70%'>\n",
    "\n",
    "                                      \n",
    "A schematic display of 5-fold CV. \n",
    "A set of n observations is randomly split into five non-overlapping groups. Each of these fifths acts as a validation set (shown in beige), and the remainder as a training set (shown in blue). The test error is estimated by averaging the five resulting MSE estimates.\n",
    "                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "9CNDLP-LMo_a",
    "outputId": "e473585f-3ff8-4e86-8894-e5550595c4b7"
   },
   "outputs": [],
   "source": [
    "# Split the data using KFold cross validation\n",
    "kfold = model_selection.KFold(n_splits=3, random_state=123)\n",
    "data = list(range(0,9))\n",
    "print(\"Data:\",data)\n",
    "for train, test in kfold.split(data):\n",
    "    print(\"Train: \", train, 'Test:', test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "fCjB1QfWMo_d",
    "outputId": "652edee1-318a-4395-f00f-fc8977dd6e3f"
   },
   "outputs": [],
   "source": [
    "# Perform k-fold cross validation\n",
    "LR = LogisticRegression(solver='liblinear')\n",
    "\n",
    "result = LR.fit(X,y)\n",
    "print(LR)\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=10)\n",
    "results = model_selection.cross_val_score(LR, X, y, cv=kfold, scoring='roc_auc')\n",
    "\n",
    "print('Model score = %.4f (%.4f)' %(results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rO8CE5F6Mo_g"
   },
   "source": [
    "### 7.42 Bootstrap\n",
    "\n",
    "Bootstrap theory says that the distance between the population mean and sample mean is similar to the distance between sample mean and bootstrap ‘subsample’ mean. \n",
    "\n",
    "\n",
    "- “To Pull Oneself up by one’s bootstraps” – Rudoph Erich Raspe\n",
    "\n",
    "- A flexible and powerful statistical tool that can be used to quantify the uncertainty associated with a given estimator or statistical learning method¹\n",
    "\n",
    "- Allows us to use a computer to mimic the process of obtaining new data set without generating additional samples (sampling with replacement).\n",
    "\n",
    "- A new model is trained on a subset of the data and uses the remaining test data to score the model.  The scores are averaged over many iterations to produce the model score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yDwA6AnAMo_g"
   },
   "source": [
    "## Bootstrap Example\n",
    "\n",
    "A graphical illustration of the bootstrap approach on a small sample containing n = 3 observations. Each bootstrap data set contains n observations, sampled with replacement from the original data set. Each bootstrap data set is used to obtain an estimate of α¹.\n",
    "\n",
    "![Bootstrap](https://github.com/joh06288/AMIA2019_W07/blob/master/images/bootstrap.png?raw=1)\n",
    "\n",
    "<sub>¹James, G., Witten, D., & Hastie, T. (2013). An introduction to statistical learning with applications in R. New York: Springer New York.</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "ADNsavaFMo_h",
    "outputId": "c4376310-f532-43ac-9dbc-4cf72d04e9e8"
   },
   "outputs": [],
   "source": [
    "# Bootstrap with replacement\n",
    "\n",
    "data = np.array(range(0,9))\n",
    "print(\"Data:\",data)\n",
    "\n",
    "bootstrap = []\n",
    "for i in [0,3]:  # 3 splits, 70% sample\n",
    "    indexes = np.random.choice(len(data),int(0.7*len(data)),replace=True)\n",
    "    bootstrap.append(list(data[indexes]))\n",
    "\n",
    "for train in bootstrap:\n",
    "    print(\"Train: \", train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "x0zMDtZOMo_k",
    "outputId": "83d15ea9-d82a-4139-f1b0-78b47d889f83"
   },
   "outputs": [],
   "source": [
    "# Perform bootstrap (with replacement)\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bootstrap = BaggingClassifier(LogisticRegression(solver='liblinear'), n_estimators=3, max_samples=0.7, \n",
    "                              bootstrap=True, random_state=123)\n",
    "fit = bootstrap.fit(X,y)\n",
    "print(bootstrap)\n",
    "\n",
    "score = bootstrap.score(X,y)\n",
    "print(\"Model score = \",score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "Vchq3siTMo_n",
    "outputId": "c9c74da9-fd4e-4854-8ef6-8b933ecd0bfa"
   },
   "outputs": [],
   "source": [
    "# Perform bootstrap (without replacement)\n",
    "LR = LogisticRegression(solver='liblinear')\n",
    "\n",
    "result = LR.fit(X,y)\n",
    "print(LR)\n",
    "\n",
    "bootstrap = model_selection.ShuffleSplit(10, test_size=0.3)\n",
    "results = model_selection.cross_val_score(LR, X, y, cv=bootstrap, scoring='roc_auc')\n",
    "\n",
    "print('Model score = %.4f (%.4f)' %(results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W8U_ew8EMo_q"
   },
   "source": [
    "# 8.0 Ok Finally, Let's Build Lots of Models! \n",
    "\n",
    "Now that we now how to avoid some of the predictive model building pitfalls, lets build a number of different types of models and meaasure their performance.  We will use \"AUC\" as our performance measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "xVJqv69cMo_r",
    "outputId": "cc100fa5-5f67-4391-cf41-d9a333a5f532"
   },
   "outputs": [],
   "source": [
    "# prepare configuration for cross validation test harness \n",
    "# (from https://machinelearningmastery.com/compare-machine-learning-algorithms-python-scikit-learn/)\n",
    "seed = 123\n",
    "# prepare models\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='liblinear')))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('RF', RandomForestClassifier(n_estimators=10)))\n",
    "models.append(('NB', GaussianNB()))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'roc_auc' \n",
    "# others include: 'accuracy', 'f1', 'roc_auc', \n",
    "# or found here: http://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, y_train, \n",
    "                                                 cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "id": "ts_sONlPMo_u",
    "outputId": "398fa6b2-a4eb-47ae-fb07-85b1562575d5"
   },
   "outputs": [],
   "source": [
    "# boxplot algorithm comparison\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "plt.ylabel(scoring)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ElA6Su2wMo_x"
   },
   "source": [
    "### Which model did \"best\"?  \n",
    "\n",
    "We'll tackle this more in the next section on **Model Performance and Evaluation.**  \n",
    "\n",
    "For now, just let's say *higher* is *better*.  \n",
    "\n",
    "### *Exercise:* Look at F1 scores instead of AUC scores. \n",
    "\n",
    "Hint: You can specify different scores like 'roc_auc', 'f1', 'precision', 'recall', etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "xmuky0VRMo_y",
    "outputId": "25079a0a-9d3c-4936-d1d4-6f23320eefd0"
   },
   "outputs": [],
   "source": [
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "####### EDIT HERE #######\n",
    "#scoring = '???'\n",
    "#########################\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, y_train, \n",
    "                                                 cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "colab_type": "code",
    "id": "Egou12ohMo_z",
    "outputId": "53bc0e39-9575-43da-bb9d-24e4a10a92bd"
   },
   "outputs": [],
   "source": [
    "# boxplot algorithm comparison\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "plt.ylabel(scoring)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CEbNIKtZMo_1"
   },
   "source": [
    "### 8.1 Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "id": "GaIFU7pcMo_2",
    "outputId": "75429737-fb20-44b3-bf47-d67f17cfbc32"
   },
   "outputs": [],
   "source": [
    "# look at the default settings you used\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d2TSpugOMo_4"
   },
   "source": [
    "### *Exercise:* Attempt parameter tuning on your own\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oHS4hyJ6Mo_5"
   },
   "outputs": [],
   "source": [
    "# use Logistic Regression & Random Forests \n",
    "models = []\n",
    "\n",
    "####### EDIT HERE #######\n",
    "#models.append(('LR', LogisticRegression(solver='liblinear')))\n",
    "#models.append(('RF', RandomForestClassifier(n_estimators=10)))\n",
    "#########################\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "####### EDIT HERE #######\n",
    "#scoring = '?????'\n",
    "#########################\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, y_train, \n",
    "                                                 cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wKwNzSLpMo_6"
   },
   "source": [
    "### scikit-learn can help with parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "NiMy57OhMo_7",
    "outputId": "db67b9ef-a5fd-4dd1-9b5e-bd50647dc7a5"
   },
   "outputs": [],
   "source": [
    "### automated grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "        {'n_estimators': [50, 100, 250], \n",
    "         'class_weight': [None, 'balanced'], \n",
    "         'max_features': [2, 'sqrt', None]}\n",
    "]\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(rfc, param_grid, cv=5, scoring='f1')\n",
    "grid_search.fit(X_train, y_train)\n",
    "cvres = grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "-B0YO8cqMo_8",
    "outputId": "4823794f-23e7-444f-ec68-1ebc711e3f04"
   },
   "outputs": [],
   "source": [
    "# print results\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(round(np.sqrt(mean_score), 3), params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1ic9ZAFAMo_-"
   },
   "source": [
    "### 8.2 Finalizing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0XcxxgLOMo__"
   },
   "outputs": [],
   "source": [
    "# assign parameters from best fit\n",
    "final_fit = RandomForestClassifier(class_weight=None, \n",
    "                                   max_features=2, \n",
    "                                   n_estimators=100)\n",
    "\n",
    "final_fit.fit(X_train, y_train)\n",
    "\n",
    "# store predicted values using the final model\n",
    "pred_train = final_fit.predict(X_train)\n",
    "pred_test = final_fit.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "id": "gcP_tW8rMpAA",
    "outputId": "02e49069-ce38-4be9-b0ea-ca6c51519cc0"
   },
   "outputs": [],
   "source": [
    "# explore performance on training data\n",
    "pd.crosstab(y_train, pred_train, \n",
    "            rownames=[\"Actual\"], colnames=[\"Predicted\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "id": "pWYfKpLbMpAD",
    "outputId": "d22d3bc8-cdbd-471c-a00b-a46284070475"
   },
   "outputs": [],
   "source": [
    "# explore performance on testing data\n",
    "pd.crosstab(y_test, pred_test, \n",
    "            rownames=[\"Actual\"], colnames=[\"Predicted\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "slXfAy1IMpAF",
    "outputId": "23eb11a4-b92b-45d2-dca1-6b337bfb4337"
   },
   "outputs": [],
   "source": [
    "# Show how to use the resulting model to predict opioid overdose\n",
    "# age, opioid_discharge_days_supply, prior_opioid_abuse_diag, \n",
    "# gender (F), marital (M), race (white), ethnicity (english)\n",
    "new_patient = [45,10,1,0,1,4,7]\n",
    "\n",
    "pred = final_fit.predict(np.asmatrix(new_patient))\n",
    "if pred[0] == 0:\n",
    "    print('Patient has no overdose risk.')\n",
    "elif pred[0] == 1:\n",
    "    print('Patient has overdose risk.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8fq4l1IQMpAH"
   },
   "source": [
    "---\n",
    "## References\n",
    "\n",
    "- [`scikit-learn` user's guide](http://scikit-learn.org/stable/user_guide.html)\n",
    "- Vanderplas, J. (2016) [Python Data Science Handbook: Essential Tools for Working with Data](http://shop.oreilly.com/product/0636920034919.do). O'Reilly Media.\n",
    "- Much of this content can be attributed to the work of Chris Fonnesbeck with source data found at: https://github.com/fonnesbeck/Bios8366"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "AMIA2019_W07_Modeling_Techniques.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
