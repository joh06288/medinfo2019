{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/joh06288/AMIA2019_W07/blob/master/AMIA2019_W07_Data_Prep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "38_akjH_uM9x"
   },
   "source": [
    "# Exploratory Data Analysis and Data Preparation\n",
    "\n",
    "## Medinfo 2019\n",
    "### Data Science Workshop\n",
    "#### August 26, 2019\n",
    "\n",
    "### Content Development: Steve Johnson, Lisiane Pruinelli, Alvin Jeffery, Tamara Winden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZMOIsxe_NguU"
   },
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mplot\n",
    "%matplotlib inline\n",
    "import IPython\n",
    "from IPython.core.display import HTML\n",
    "from IPython.core.debugger import set_trace\n",
    "from distutils.version import StrictVersion\n",
    "print(\"numpy version:  %s\" % np.__version__)\n",
    "print(\"pandas version:  %s\" % pd.__version__)\n",
    "print(\"matplotlib version:  %s\" % mplot.__version__)\n",
    "print(\"IPython version:  %s\" % IPython.__version__)\n",
    "print(\"seaborn version:  %s\" % sns.__version__)\n",
    "\n",
    "if StrictVersion(np.__version__) >= StrictVersion('1.13.0') and \\\n",
    "   StrictVersion(pd.__version__) >= StrictVersion('0.20.0') and \\\n",
    "   StrictVersion(mplot.__version__) >= StrictVersion('2.0.0') and \\\n",
    "   StrictVersion(IPython.__version__) >= StrictVersion('5.5.0') and \\\n",
    "   StrictVersion(sns.__version__) >= StrictVersion('0.7.0'):\n",
    "    print('\\nCongratulations, your environment is setup correctly!')\n",
    "else:\n",
    "    print('\\nEnvironment is NOT setup correctly!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AVqO021euWsf"
   },
   "outputs": [],
   "source": [
    "# Try to install the Excel reader library (its not pre-installed on Colab)\n",
    "try:\n",
    "    import xlrd\n",
    "    print('The Excel library is installed.')\n",
    "except ImportError:\n",
    "    print('Installing the Excel library')\n",
    "    !pip install xlrd\n",
    "    import xlrd\n",
    "# Try to install the Bokeh library (its not pre-installed on Colab)\n",
    "try:\n",
    "    import bokeh\n",
    "    print('The Bokeh library is installed.')\n",
    "except ImportError:\n",
    "    print('Installing the Bokeh library')\n",
    "    !pip install bokeh\n",
    "    import bokeh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jWSv1aAZNgua"
   },
   "source": [
    "### 1.1 Check data directory\n",
    "\n",
    "See if the data exists.  If not, try to download it from github."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QDvLFJcIxaah"
   },
   "source": [
    "# 1.0 Setup\n",
    "\n",
    "Ensure that your Jupyter environment is setup correctly and import all of the data science libraries that we will need.  If some modules are missing, we will attempt to install the library but it is usually a better practice to install it in your environment directly.\n",
    "\n",
    "Also, if the data is missing, we will attempt to download it (from github) and put it in the \"/data_oh\" subdirectory of your current working directory (Ohio synthetic data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EqZAggVouWsk"
   },
   "outputs": [],
   "source": [
    "# Find the data directory and download data if it is missing\n",
    "\n",
    "import os, shutil\n",
    "cwd = os.getcwd()\n",
    "datadir = cwd + '/data_oh'\n",
    "\n",
    "print('Data directory is: {}'.format(datadir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zXEsr7EO5H-v"
   },
   "outputs": [],
   "source": [
    "# See if the data exists.  If not, try to download it from github.\n",
    "if not os.path.exists(datadir+'/patients.csv'):\n",
    "    print(\"Data directory doesn't exist!\")\n",
    "    print(\"Checking out the data from github...\")\n",
    "\n",
    "    !git clone https://github.com/joh06288/Medinfo2019.git\n",
    "        \n",
    "    # Move the checked-out files into the /data directory\n",
    "    files = os.listdir('Medinfo2019')\n",
    "    for f in files:\n",
    "        print('Moving %s...' % (f,))\n",
    "        try:\n",
    "            shutil.move('Medinfo2019/'+f,'.')\n",
    "        except:\n",
    "            print(\"    Unable to move %s\" % (f,))\n",
    "            \n",
    "    try:\n",
    "        shutil.rmtree('Medinfo2019')  # Remove the version control (git) information\n",
    "    except:\n",
    "        pass  # Ignore errors.  On Windows, this sometimes fails and leaves the .git directory\n",
    "print('Data directory contains:\\n',os.listdir(datadir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KZA3W-hhxkpV"
   },
   "source": [
    "# 2.0 Read in the data\n",
    "\n",
    "Now that we have all the libraries installed and the data is available, lets try to read it into Pandas DataFrames.  \n",
    "\n",
    "The first thing we will do is define a Data Dictionary (dd) that describes our expectations for the data.  It includes data types for the columns as well is information about whether the column is required or optional.  The data is read into a dictionary of Dataframes (data) and also assigned to  variables (patients, encounters, etc) for convenience.\n",
    "\n",
    "We will convert dates and other fields to the proper format when later when we do data preparation.\n",
    "\n",
    "The dataset is synthetic data generated by the Synthea project (https://github.com/synthetichealth/synthea).  Synthea creates realistic (but not real) EHR-like data that we can use for demonstrating the techniques of data science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U3ymTsiKuWsn"
   },
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "dd = {}\n",
    "\n",
    "dd['patients'] = {'pat_id':     {'type': np.str, 'required':True},  \n",
    "                  'birth_date': {'type': np.datetime64, 'format': '%Y-%m-%d', 'required':True},\n",
    "                  'death_date': {'type': np.datetime64, 'format': '%Y-%m-%d' }, \n",
    "                  'ssn':        {'type': np.str},\n",
    "                  'drivers':    {'type': np.str},\n",
    "                  'passport':   {'type': np.str},\n",
    "                  'prefix':     {'type': np.str},\n",
    "                  'first':      {'type': np.str, 'required':True},\n",
    "                  'last':       {'type': np.str, 'required':True},\n",
    "                  'suffix':     {'type': np.str},\n",
    "                  'maiden':     {'type': np.str},\n",
    "                  'marital':    {'type': np.str},\n",
    "                  'race':       {'type': np.str},\n",
    "                  'ethnicity':  {'type': np.str},\n",
    "                  'gender':     {'type': np.str, 'required':True},\n",
    "                  'birthplace': {'type': np.str},\n",
    "                  'address':    {'type': np.str, 'required':True},\n",
    "                  'prior_opioid_abuse_diag': {'type': np.int}\n",
    "                  }\n",
    "dd['encounters'] = {'enc_id':                 {'type': np.str, 'required':True}, \n",
    "                    'enc_date':               {'type': np.datetime64, 'format': '%Y-%m-%d', 'required':True},\n",
    "                    'enc_pat_id':             {'type': np.str, 'required':True},\n",
    "                    'enc_code':               {'type': np.str, 'required':True},\n",
    "                    'enc_description':        {'type': np.str, 'required':True},\n",
    "                    'enc_reason_code':        {'type': np.str},\n",
    "                    'enc_reason_description': {'type': np.str}\n",
    "                   }\n",
    "dd['observations'] = {'obs_date':        {'type': np.datetime64, 'format': '%Y-%m-%d', 'required':True},\n",
    "                      'obs_pat_id':      {'type': np.str, 'required':True},\n",
    "                      'obs_enc_id':      {'type': np.str, 'required':True},\n",
    "                      'obs_code':        {'type': np.str, 'required':True},\n",
    "                      'obs_description': {'type': np.str, 'required':True},\n",
    "                      'obs_value':       {'type': np.str},\n",
    "                      'obs_units':       {'type': np.str}\n",
    "                     }\n",
    "dd['medications'] = {'med_start_date':         {'type': np.datetime64, 'format': '%Y-%m-%d', 'required':True},\n",
    "                     'med_stop_date':          {'type': np.datetime64, 'format': '%Y-%m-%d', 'required':False},\n",
    "                     'med_pat_id':             {'type': np.str, 'required':True},\n",
    "                     'med_enc_id':             {'type': np.str, 'required':True},\n",
    "                     'med_code':               {'type': np.str, 'required':True},\n",
    "                     'med_description':        {'type': np.str, 'required':True},\n",
    "                     'med_reason_code':        {'type': np.str},\n",
    "                     'med_reason_description': {'type': np.str},\n",
    "                     'med_days_supply':        {'type': np.int}\n",
    "                     }\n",
    "dd['conditions'] =  {'cond_start_date':         {'type': np.datetime64, 'format': '%Y-%m-%d', 'required':True},\n",
    "                     'cond_stop_date':          {'type': np.datetime64, 'format': '%Y-%m-%d', 'required':False},\n",
    "                     'cond_pat_id':             {'type': np.str, 'required':True},\n",
    "                     'cond_enc_id':             {'type': np.str, 'required':True},\n",
    "                     'cond_code':               {'type': np.str, 'required':True},\n",
    "                     'cond_description':        {'type': np.str, 'required':True}\n",
    "                     }\n",
    "\n",
    "\n",
    "# Display the data dictionary\n",
    "# Use HTML to make it look a little nicer\n",
    "\n",
    "for name, tbl_dd in dd.items():\n",
    "    display(HTML('<h2>{}</h2>'.format(name)))\n",
    "    display(pd.DataFrame(tbl_dd).fillna('').T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n3-p3h8lP7jR"
   },
   "outputs": [],
   "source": [
    "# Loop through each of the file defintions in our data dictionary\n",
    "data = {}\n",
    "for f in dd:\n",
    "    m = dd[f]\n",
    "    col_names = list(m.keys())\n",
    "    data[f] = pd.read_csv(datadir + '/{}.csv'.format(f), dtype=str, index_col=False, header=0, \\\n",
    "                          names=col_names, keep_default_na=False)\n",
    "\n",
    "# Assign data to local variables for convenience\n",
    "patients = data['patients']\n",
    "encounters = data['encounters']\n",
    "observations = data['observations']\n",
    "medications = data['medications']\n",
    "conditions = data['conditions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UrTsAUkgHhPo"
   },
   "outputs": [],
   "source": [
    "# Display the first 3 patients\n",
    "patients.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D1JPSmHRHtdn"
   },
   "source": [
    "## Exercise: Display the last 3 patients\n",
    "\n",
    "Hint: the \"tail\" method displays the last part of a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SPL8IN7UHpxF"
   },
   "outputs": [],
   "source": [
    "# Display the last 3 patients\n",
    "#???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oqtssqpRNgun"
   },
   "source": [
    "### 2.1 Load the list of opioid medications\n",
    "\n",
    "It will be important to know which of the medications that are prescribed are considered opioids.  The UMLS VSAC maintains value set lists of which medications are considered opioids.  You can download the current list by going to https://vsac.nlm.nih.gov/ and searching for opioid value sets.  We have downloaded the list called \"All prescribable opioids used for pain control including Inactive Medications\" (oid 1.3.6.1.4.1.6997.4.1.2.234.999.3.2) into the data directory.  We will read the Excel file and pull out the codes from the second sheet in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6ygbd4wpNguo"
   },
   "outputs": [],
   "source": [
    "# Get Opioid code list from VSAC\n",
    "# oid 1.3.6.1.4.1.6997.4.1.2.234.999.3.2\n",
    "xl = pd.ExcelFile(datadir + '/AllPrescribableOpioidsUsedForPainControlIncludingInactiveMedications.xlsx')\n",
    "df = xl.parse(\"Code List\", skiprows=12)\n",
    "display(df.head(10))\n",
    "opioids_rxnorm = list(df['Code'].astype(np.str))  # Make sure the codes are treated as strings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YwLnaiLiLjba"
   },
   "source": [
    "# 3.0 Exploratory Data Analysis - Part 1\n",
    "\n",
    "Start by looking at the data to see what types of values are in each variables, the relationships and get a feel for the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "49JYp6fJNgur"
   },
   "source": [
    "### 3.1 Start by displaying the data as DataFrames\n",
    "\n",
    "Displaying the first few rows of the data is a good way to look for obvious issues before working with the data in more detail.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LvwqJrjoNgur",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loop through each of the file defintions in our data dictionary\n",
    "for f in dd:\n",
    "    m = dd[f]\n",
    "    display(HTML('<h3>{}, {} records</h3>'.format(f,len(data[f]))))\n",
    "    display(data[f].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aGCEQhDEuM-M"
   },
   "outputs": [],
   "source": [
    "# You can also display the last few rows using the .tail() function.\n",
    "patients.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CeWIcZZquM-O"
   },
   "source": [
    "### 3.2 Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oxb4DG_nMDwv"
   },
   "outputs": [],
   "source": [
    "# Look at the categorical variables\n",
    "\n",
    "sns.countplot(x='race', data=patients)\n",
    "plt.title('Race')\n",
    "plt.show()\n",
    "\n",
    "sns.countplot(x='obs_code',data=observations)\n",
    "plt.title('Observation Codes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x5B-bTiDuM-R"
   },
   "outputs": [],
   "source": [
    "# The observations are hard to read, lets try a bar plot\n",
    "c = observations['obs_description'].value_counts(ascending=True)\n",
    "fig = plt.figure(figsize=(8,24))\n",
    "c.plot(kind=\"barh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Vxz4SVvuM-U"
   },
   "source": [
    "### 3.3 Continuous Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xyC32Qx1uM-U"
   },
   "outputs": [],
   "source": [
    "# We can get statistics for the continuous variables using the .describe() function\n",
    "patients.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XOOgSrclNguy"
   },
   "outputs": [],
   "source": [
    "# For continuous variables, we can graph the distribution\n",
    "\n",
    "w = observations[observations['obs_code']=='29463-7']   # Find all of the \"weight\" observations\n",
    "weights = w['obs_value'].astype(np.float).dropna()\n",
    "mean = np.mean(weights)\n",
    "print('Average weight: ',mean)\n",
    "\n",
    "# Plot the distribution\n",
    "sns.kdeplot(weights)\n",
    "plt.xlabel(\"WEIGHT (kg)\")\n",
    "plt.show()   # If you don't explicitly \"show\" the plot, Jupyter will automatically show the last plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jeq6D_uSuM-c"
   },
   "source": [
    "### Use Sort and Display\n",
    "\n",
    "This graph looks a little odd.  We have 2 peaks which are expected.  This corresponds to the average weight of a child vs average weight of an adult.  However, we have some values that seem to go all the way to 1400 Kg.  That doesn't seem right.  Let's take a closer look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zAP7sLTauM-e"
   },
   "outputs": [],
   "source": [
    "# Show the highest 20 weights\n",
    "print(weights.sort_values(ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wHn3j0bHuM-h"
   },
   "source": [
    "### Drop outliers\n",
    "\n",
    "It doesn't seem reasonable that someone weighs 1321.8 Kg.  So let's drop anything above 500 Kg.  We will use the Pandas Boolean Indexing to create a filter.  You can specify an arbitrary condition which is applied to each row in the DataFrame and only returns those rows that satisfy the conditional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WvIK1GrzuM-i"
   },
   "outputs": [],
   "source": [
    "weights = weights[weights <= 500]\n",
    "print(weights.sort_values(ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P6mhJE3buM-k"
   },
   "outputs": [],
   "source": [
    "# Let's re-plot the distribution\n",
    "sns.kdeplot(weights, shade=True, color='blue')\n",
    "plt.xlabel(\"WEIGHT (kg)\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jIdA5A66_B_s"
   },
   "source": [
    "## Exercise:  Graph the Height of Patients and color it Red\n",
    "\n",
    "Hint: LOINC code for height is 8302-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7lz_KGneNgu0"
   },
   "outputs": [],
   "source": [
    "# As an Exercise, graph the Height of patients\n",
    "\n",
    "h = observations[observations['obs_code']=='xxxx']   \n",
    "heights = h['obs_value'].astype(np.float).dropna()\n",
    "#sns.kdeplot(heights,shade=True,color='???')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5-xiAaMhNgu2"
   },
   "source": [
    "# 4.0 Data Preparation\n",
    "\n",
    "##### Now that we know a little about our data, we can begin to prepare it for analysis.  Understanding Data Quality is important before you can start working with your data.\n",
    "\n",
    "### Data Quality\n",
    "#### Dimensions\n",
    "- Correctness – Does the data represent a truth about the world?\n",
    " - Birth_date = “1/3/1990”\n",
    "- Completeness – Is data missing?\n",
    " - Death_date = NULL\n",
    "- Consistency – Does data conform to expectations / rules?\n",
    " - Birth_date = “1/3/1990”, death_date = “1/2/1990”\n",
    "  - Rule: birth_date must be <= death_date\n",
    "- Currency – Is the data timely and up-to-date?\n",
    " - Data updated at end of shift?  Nightly load into CDR?\n",
    " \n",
    "#### Document data expectations \n",
    "\n",
    "#### Required data quality depends on fitness-for-use\n",
    "- Count patients vs count diabetic patients with controlled A1c\n",
    "\n",
    "\n",
    "### Dealing with Missing Data\n",
    "#### Decide on consistent way to handle missing data\n",
    "- Remove “rows” with missing values\n",
    "- Fill in missing values\n",
    " - Constant (i.e. ”0”)\n",
    " - Use the Mean\n",
    " - Multiple Imputation / Regression\n",
    " - Last value\n",
    "- Missingness may be meaningful\n",
    " - MCAR – missingness unrelated to the variable\n",
    "  - The lab lost a sample so results aren’t reported\n",
    " - MAR – missingness related to another variable\n",
    "  - Female patients in pain may under report vs Male patients\n",
    " - MNAR – missingness related to the variable\n",
    "  - Patients with severe depression may not answer survey depression questions\n",
    "\n",
    "##### For this workshop, we will address Data Quality issues by:\n",
    "1. Find data that is not formatted correctly\n",
    "2. Deal with missing data\n",
    "\n",
    "In all of these cases, we will have to decide what to do with the bad data.  We can:\n",
    "1. Delete the data\n",
    "2. Impute a reasonable value for the missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dn9X4BCjNgu8"
   },
   "outputs": [],
   "source": [
    "# Find data that is not formatted correctly\n",
    "\n",
    "def parse_date(dt,fmt):\n",
    "    if type(dt) == str and (dt == ''):\n",
    "        return dt\n",
    "    try:\n",
    "        return pd.to_datetime(dt,format=fmt)\n",
    "    except:\n",
    "        return np.datetime64('NaT')\n",
    "\n",
    "def parse_int(num):\n",
    "    if type(num) == str and (num == ''):\n",
    "        return num\n",
    "    try:\n",
    "        return int(num)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# Loop through our Data Dictionary\n",
    "for name, tbl_dd in dd.items():\n",
    "    display(HTML('<h2>{}</h2>'.format(name)))\n",
    "    d = data[name]\n",
    "    for field_name, field in tbl_dd.items():\n",
    "        col = d[field_name]\n",
    "        field['DQ'] = {}\n",
    "        field['DQ']['missing'] = len(np.where(col == '')[0])\n",
    "\n",
    "        if field['type'] == np.datetime64:\n",
    "            if 'format' in field:\n",
    "                fmt = field['format']\n",
    "            else:\n",
    "                fmt = '%Y-%m-%d'   # Default date format if not specified\n",
    "                \n",
    "            d[field_name] = col.apply(lambda x: parse_date(x,fmt))\n",
    "            field['DQ']['format_errors'] = col.isnull().sum()\n",
    "        elif field['type'] == np.int:\n",
    "            d[field_name] = col.apply(lambda x: parse_int(x))\n",
    "            field['DQ']['format_errors'] = col.isnull().sum()\n",
    "        elif field['type'] == np.str:\n",
    "            pass # Everything is valid syntax\n",
    "            field['DQ']['format_errors'] = 0\n",
    "            \n",
    "    # Show the Data Quality information\n",
    "    display(pd.DataFrame(dd[name]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Hc0Hg-uuM-u"
   },
   "source": [
    "### 4.2 Drop unwanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mY2UTPgSuM-v"
   },
   "outputs": [],
   "source": [
    "# Let's remove some of the data that we won't need to use for the workshop\n",
    "# It will make some of the screens easier to read\n",
    "# Put it in a try block in case we've already dropped the columns\n",
    "try:\n",
    "    patients.drop(['maiden','passport','drivers','prefix','suffix','ssn','first','last'],axis=1,inplace=True)\n",
    "except:\n",
    "    pass\n",
    "display(patients.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bAMV4AQbuM-x"
   },
   "source": [
    "### 4.3 Remove rows with missing data\n",
    "\n",
    "For this workshop, we will only deal with missing data by dropping it.  If a row has missing or bad formatted data and the field is required, we will drop the entire row.\n",
    "\n",
    "An alternative is to try to fix the data by imputing a reasonable value for it, such as the column .mean()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IWwIx3NYNgvF"
   },
   "outputs": [],
   "source": [
    "# The .isnull() functions are used to find bad data\n",
    "# The .any() function returns the columns that contain any True values\n",
    "\n",
    "display(patients.isnull().head(5))\n",
    "display(patients.isnull().any())\n",
    "\n",
    "# Let's get a list of all of the columns with some missing data \n",
    "missing_cols=patients.columns[patients.isnull().any()]\n",
    "print(missing_cols)\n",
    "\n",
    "# We can see how many cells have missing data for each column\n",
    "patients[missing_cols].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GIdyBRn8uM-0"
   },
   "outputs": [],
   "source": [
    "# Drop missing or incorrectly formatted data for the required patient data fields\n",
    "\n",
    "# Get the row numbers (index) of each of the rows with missing data\n",
    "missing = patients[patients.isnull().any(axis=1)].index\n",
    "print(\"Missing = \",missing)\n",
    "print('Before patients shape = ',patients.shape)\n",
    "patients.drop(missing,inplace=True)\n",
    "\n",
    "# Make sure the rows are gone\n",
    "missing = patients[patients.isnull().any(axis=1)].index\n",
    "print(\"Missing = \",missing)\n",
    "print('After patients shape = ',patients.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rVVDeJqpMSK6"
   },
   "source": [
    "### 4.4 Transform the Data\n",
    "\n",
    "Use the power of Pandas Dataframes to transform the data.  Add new columns as calculations from existing columns, join the data together and get it into the format you need for analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mu-qPMysNgvP"
   },
   "outputs": [],
   "source": [
    "# Create the working dataframe\n",
    "\n",
    "df = patients\n",
    "df['age'] = round((pd.Timestamp.today() - pd.to_datetime(patients['birth_date'])).dt.days/365)\n",
    "df['adult'] = np.where(df['age'] >= 18, 1, 0)\n",
    "\n",
    "# Determine which patients have ever overdosed\n",
    "# Use a set to eliminate duplicates\n",
    "patients_that_overdosed = set(encounters[encounters['enc_reason_code']=='55680006']['enc_pat_id'])  # Overdose\n",
    "df['overdose'] = np.where(df['pat_id'].isin(patients_that_overdosed), 1, 0)\n",
    "\n",
    "# Determine which patients were ever prescribed opioids\n",
    "patients_prescribed_opioids = set(medications[medications['med_code'].isin(opioids_rxnorm)]['med_pat_id'])  # Opioids\n",
    "df['prescribed_opioids'] = np.where(df['pat_id'].isin(patients_prescribed_opioids), 1, 0)\n",
    "\n",
    "print('Num patients prescribed opioids = {}, Num overdoses = {}'\n",
    "         .format(len(patients_prescribed_opioids),len(patients_that_overdosed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DJK-PID-uM-6"
   },
   "outputs": [],
   "source": [
    "# Determine which patients have died from an overdose\n",
    "# Uses binary indexing\n",
    "obs = observations[(observations['obs_code'] == '69453-9') &   # Death\n",
    "                                (observations['obs_value'].str.contains('overdose'))]\n",
    "print('Example of an overdose death observation:')\n",
    "display(pd.DataFrame(obs.iloc[0,:]))\n",
    "patients_overdose_deaths = set(obs['obs_pat_id'])\n",
    "print('Number of overdose deaths = {}'.format(len(patients_overdose_deaths)))\n",
    "print('Here are the overdose deaths:')\n",
    "display(df[df['pat_id'].isin(patients_overdose_deaths)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iXdxuyM5MeIG"
   },
   "source": [
    "### 4.5 Compute the days_supply variable\n",
    "\n",
    "We want to compute how many days supply of a medication a patient was prescribed at discharge.  The approach we will use is that for each encounter, we will find all of the medications associated with the encounter.  We will look for medications that are opioids and find the largest days supply for that encounter and store the result in the 'opioid_discharge_days_supply' column.\n",
    "\n",
    "This is most easily accomlished using a function that defines the logic and the \".apply\" DataFrame function the will iterate over each row in a DataFrame, call the function and store the result back in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HF7nIZwfNgvS"
   },
   "outputs": [],
   "source": [
    "# Define the function that will perform to logic of compute the discharge opioid days supply\n",
    "\n",
    "def get_days_supply(pat_id):\n",
    "    enc_meds = medications[medications['med_pat_id'] == pat_id]\n",
    "    enc_opioid_meds = enc_meds[enc_meds['med_code'].isin(opioids_rxnorm)]\n",
    "    max = 0\n",
    "    if len(enc_opioid_meds) > 0:\n",
    "        try:\n",
    "            max = int(enc_opioid_meds['med_days_supply'].max())\n",
    "        except ValueError:\n",
    "            max = 0\n",
    "    return int(max)\n",
    "\n",
    "# Apply the function to each row (Note: this can take a little while to finish)\n",
    "df['opioid_discharge_days_supply'] = df.apply(lambda x: get_days_supply(x['pat_id']), axis=1)\n",
    "\n",
    "# Display the first 5 entries that have a non-zero days supply, just to check our logic\n",
    "df[df['opioid_discharge_days_supply'] > 0].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iUQv5J0wuM--"
   },
   "source": [
    "### 4.6 Save our Clean Data\n",
    "\n",
    "It is a good practice to save your clean data so that you don't have to keep re-cleaning it everytime you want to use it.  Pandas (and Python) provides a function to save a variable in a special format that can be easily recreated later.  This is called 'pickling' in Python.  So we will save our cleaned DataFrame, df, to be used by subsequent notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4RolfLzJuM-_"
   },
   "outputs": [],
   "source": [
    "# Pickle the data \n",
    "df.to_pickle(datadir+'/data_cleaned_oh.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2An5P7D0NgvU"
   },
   "source": [
    "# 5.0 Explore the Data - Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations\n",
    "### Visualization Best Practices\n",
    "#### Tufte's 6 Principles of Graphical Integrity\n",
    "- Representation of numbers should match the true proportions.\n",
    "- Labeling should be clear and detailed.\n",
    "- Design should not vary for some ulterior motive, show only data variation.\n",
    "- To represent money, well known units are best.\n",
    "- The number of dimensions represented should be the same as the number of dimensions in the data.\n",
    "- Representations should not imply unintended context.\n",
    "\n",
    "Source: Tufte ER. The visual display of quantitative information. Cheshire, CT: Graphics press; 2001 Jan\n",
    "\n",
    "### Types of Visualizations\n",
    "![Types](images/TypesOfVisualizations.png)\n",
    "Source:  https://extremepresentation.typepad.com/files/choosing-a-good-chart-09.pdf\n",
    "\n",
    "### Tell a Story\n",
    "- Use color, size,shape, proportion, progression and text callouts to tell the story\n",
    "- Uses maps to show relationships\n",
    "- Mix different visualizations to show data in the most appropriate manner\n",
    "![](images/TellAStory.png)\n",
    "Source: https://www.tableau.com\n",
    "\n",
    "### Python Visualization Tools\n",
    "- Matplotlib – Powerful, complex visualization package\n",
    " - https://matplotlib.org/2.1.1/gallery/index.html\n",
    "- Seaborn – Simplifies Matplotlib, default styles\n",
    "- Bokeh – Interactive visualization in a browser\n",
    "\n",
    "\n",
    "### Custom Visualizations\n",
    "#### d3 – Custom visualizations using JavaScript\n",
    " - https://d3js.org/  , https://bl.ocks.org/mbostock\n",
    "![](images/CustomForceDirected-d3.png)\n",
    " \n",
    "#### Build your own in Python \n",
    "![](images/CustomTimeline.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ygRWbg6_QHur"
   },
   "source": [
    "### 5.1 Outcome variable\n",
    "\n",
    "Now that we have created some new variables, lets take a look at how the outcome variable is associated with our predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8w6XYA9eNgva"
   },
   "outputs": [],
   "source": [
    "# See who overdosed from prescribed opioids by computing the intersection\n",
    "\n",
    "overlap = patients_that_overdosed.intersection(patients_prescribed_opioids)\n",
    "\n",
    "print('Num that overdose = {}, Num that were prescribed opioids = {}, overlap = {}'.format(\\\n",
    "    len(patients_that_overdosed),len(patients_prescribed_opioids),len(overlap)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DwbdILHlNgvb"
   },
   "source": [
    "How many patients overdosed?\n",
    "\n",
    "Since we store 'overdose' as a 0 or 1, we can just use the mean function to compute what percent of the population overdosed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D6W9vKMeNgvb"
   },
   "outputs": [],
   "source": [
    "overdose = df[df['pat_id'].isin(patients_prescribed_opioids)]\n",
    "display(overdose['overdose'].value_counts())\n",
    "print('Percent that overdosed: {0:.2f}%'.format(overdose['overdose'].mean()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zx9nJrr8uM_H"
   },
   "source": [
    "### 5.2 Crosstabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M2AvZvFJNgvh"
   },
   "outputs": [],
   "source": [
    "# What was the mean number of days_supply for patients that overdosed and were prescribed opioids?\n",
    "\n",
    "ct = pd.crosstab(df['prescribed_opioids'],df['opioid_discharge_days_supply'])\n",
    "display(ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w9IMDCU8uM_M"
   },
   "source": [
    "### Multiple graphs using Facetgrid\n",
    "\n",
    "We can also see multiple graphs at the same time using the Seaborn Facetgrid function.  It lets you see the same graph split by up to 2 variables.  For example, we can look at how overdose is related to age and gender and whether the patient was ever prescribed opioids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7DCAmmUmuM_Q"
   },
   "outputs": [],
   "source": [
    "p = sns.FacetGrid(df, row='overdose', col='gender', hue='prescribed_opioids', sharey=False)\n",
    "p.map(plt.hist, 'age')\n",
    "p.add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DQTjt_xaNgvj"
   },
   "source": [
    "### 5.3 Graph the patient variables against the outcome\n",
    "\n",
    "Let's see if gender, race and age are associated with the outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v6y5oqBmNgvk"
   },
   "outputs": [],
   "source": [
    "pd.crosstab(patients['gender'],patients['overdose']).plot(kind='bar')\n",
    "plt.title('Overdose by Gender')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Ii3ZGpENgvo"
   },
   "outputs": [],
   "source": [
    "pd.crosstab(patients['race'],patients['overdose']).plot(kind='bar')\n",
    "plt.title('Overdose by Race')\n",
    "plt.xlabel('Race')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R__EWwiLNgvp"
   },
   "source": [
    "We have a pretty uniform distribution of ages in the patient data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "itxkiNCNNgvp"
   },
   "outputs": [],
   "source": [
    "# Histograms are easy to create\n",
    "patients['age'].hist()\n",
    "plt.title('Histogram of Age')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qcaI-FaONgvs"
   },
   "source": [
    "### 5.4 Grouping by a variable\n",
    "\n",
    "We often want to group related rows together and then count the number rows of each type or find the mean of a variable for each row type.\n",
    "\n",
    "For example, lets count how many encounters each patient has over the timeframe of the data.  We will use the `groupby` function to group on a set of variables.  The operation returns a `groupby` object which doesn't actually group the data but instead acts like a set of instructions telling the DataFrame how to group itself.  We need to apply another function, such as size(), mean() or sum(), to the groups to yield a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EAW0QqbkLrJh"
   },
   "outputs": [],
   "source": [
    "# How many encounters does each patient have?\n",
    "\n",
    "encs = encounters.groupby(['enc_pat_id']).size()\n",
    "\n",
    "# We can store that information directly into the patients DataFrame since `encs` is indexed by the pat_id\n",
    "patients = patients.set_index('pat_id')\n",
    "patients['num_encounters'] = encs\n",
    "patients = patients.reset_index()\n",
    "\n",
    "# Visualize the number of encounters as a patient ages, use color to highlight the gender difference\n",
    "sns.lmplot(data=patients,x='age',y='num_encounters',hue='gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IZWAMdv1Ngvd"
   },
   "outputs": [],
   "source": [
    "# We can also apply a function to the groups\n",
    "df.groupby('overdose').mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1X5aAmRPNgvu"
   },
   "source": [
    "### 5.5 For those that overdose, what is the days_supply?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_g69wExxNgvu"
   },
   "outputs": [],
   "source": [
    "display(df[df['overdose']==1].mean())\n",
    "display(df[df['prescribed_opioids']==1].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P-iNFJ0dNgvx"
   },
   "source": [
    "### 5.6 What are the primary reasons for visit for patients that ever overdosed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5KOtf0EZNgvx"
   },
   "outputs": [],
   "source": [
    "encounters[encounters['enc_pat_id'].isin(patients_that_overdosed)]['enc_reason_description'].value_counts(sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DxowZvJquM_l"
   },
   "source": [
    "### 5.7 Who overdosed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dIhLzt0XNgv7"
   },
   "outputs": [],
   "source": [
    "# Who were the patients that overdosed?\n",
    "\n",
    "pt = df[df['pat_id'].isin(patients_that_overdosed)]\n",
    "\n",
    "pt.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1l2tXR5hNgv3"
   },
   "source": [
    "### 5.8 Get an idea of how a patient progresses through their healthcare\n",
    "\n",
    "When exploring the data, it helps to visualize what is happening across time.  You can create small functions within the Jupyter notebook and reuse them further down in the notebook.  \n",
    "\n",
    "In this case, we are looping through the encounter data for a patient and print all of the medications and labs (observations) that are associated with the patient.  The function `display_trajectory` is passed the id for a patient and then prints the information.  We can use this later to further examine data or debug things we don't understand.\n",
    "\n",
    "First, we will define a simple function that prints the details.  You can create little helper functions like this that are reusable and help you get familiar with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kNlJlgaCY-O2"
   },
   "outputs": [],
   "source": [
    "def display_trajectory(df,pt_id):\n",
    "    pt = patients[patients['pat_id']==pt_id]\n",
    "\n",
    "    display(pt)\n",
    "    encs = encounters[encounters.enc_pat_id == pt_id]\n",
    "    #print(encs.shape)\n",
    "    for i, e in encs.iterrows():\n",
    "        #dt = df[df['pat_id']==e['enc_pat_id']].iloc[0]\n",
    "        print('  {:%Y-%m-%d}: {} ({}) ({})'.format(e['enc_date'], e['enc_description'], \\\n",
    "                         e['enc_code'], e['enc_reason_description']))\n",
    "        meds = medications[medications['med_enc_id'] == e['enc_id']]\n",
    "        for j, m in meds.iterrows():\n",
    "            print('     MED: {:%Y-%m-%d}: {} ({}) days_supply={}'.format(m['med_start_date'],  \\\n",
    "                                            m['med_description'], m['med_code'], m['med_days_supply']))\n",
    "        labs = observations[observations['obs_enc_id'] == e['enc_id']]\n",
    "        for k, l in labs.iterrows():\n",
    "            print('     LAB: {:%Y-%m-%d %H:%M}: {} ({}) {} {}'.format(l['obs_date'], l['obs_description'], l['obs_code'], l['obs_value'], l['obs_units']))\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gF98rMhDNgv9",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Display the trajectory of one of the overdose patients\n",
    "pt_id = list(patients_that_overdosed)[1]\n",
    "display_trajectory(df,pt_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dpgmHBIQyS9a"
   },
   "source": [
    "### 5.81 Graphical Timeline\n",
    "\n",
    "We can get a higher-level overview of the data by drawing a graphical timeline using Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9uAajYaEuM_t"
   },
   "outputs": [],
   "source": [
    "# Function to display a timeline for an encounter\n",
    "\n",
    "def plot_timeline(pt_id):\n",
    "  import matplotlib.dates as mdates\n",
    "  from datetime import datetime\n",
    "\n",
    "  pt = patients[patients['pat_id']==pt_id]\n",
    "  encs = encounters[encounters.enc_pat_id == pt_id]\n",
    "\n",
    "  dates = []\n",
    "  names = []\n",
    "  for i, e in encs.iterrows():\n",
    "      names.append(e['enc_description'])\n",
    "      dates.append(e['enc_date'])\n",
    "  levels = np.array([-5, 5, -4, 4, -3, 3, -2, 2, -1, 1])\n",
    "  fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "  # Create the base line\n",
    "  ax.plot((min(dates), max(dates)), (0, 0), 'k', alpha=.5)\n",
    "\n",
    "  # Iterate through encounters and plot the event name\n",
    "  for i, (iname, idate) in enumerate(zip(names, dates)):\n",
    "      level = levels[i % len(levels)]\n",
    "      vert = 'top' if level < 0 else 'bottom'\n",
    "      ax.scatter(idate, 0, s=100, facecolor='b', edgecolor='k', zorder=9999)\n",
    "      # Plot a line up to the text\n",
    "      ax.plot((idate, idate), (0, level), c='b')\n",
    "      # Give the text a faint background and align it properly\n",
    "      ax.text(idate, level, iname,\n",
    "              horizontalalignment='right', verticalalignment=vert, fontsize=10)\n",
    "  ax.set(title=\"Timeline for Patient: %s\" % (pt_id,))\n",
    "  # 3 month intervals\n",
    "  ax.get_xaxis().set_major_locator(mdates.MonthLocator(interval=3))\n",
    "  ax.get_xaxis().set_major_formatter(mdates.DateFormatter(\"%b %Y\"))\n",
    "  fig.autofmt_xdate()\n",
    "  # Remove the y-axis labels\n",
    "  plt.setp((ax.get_yticklabels() + ax.get_yticklines() + list(ax.spines.values())), visible=False)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "16bKvqn-KG3H"
   },
   "outputs": [],
   "source": [
    "# Plot the first patient's timeline (you can even plot multiple patients)\n",
    "plot_timeline(list(patients_that_overdosed)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XzVw7F4HuM_u"
   },
   "source": [
    "### 5.9 Geographic Mapping\n",
    "\n",
    "We can also easily visualize our data geographically.  All of our patients have addresses.  We can use a library called Bokeh and Google Maps API to quickly visualize where are patients come from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ksW4UjYVuM_u"
   },
   "outputs": [],
   "source": [
    "from bokeh.io import output_notebook, show, reset_output\n",
    "from bokeh.models import (\n",
    "  GMapPlot, GMapOptions, ColumnDataSource, Circle, Range1d, PanTool, WheelZoomTool\n",
    ")\n",
    "\n",
    "# Read in the Latitude/Longitude of the patients\n",
    "patlocations = pd.read_csv(datadir + '/patlocations.csv', dtype=str, index_col=False, header=0, keep_default_na=False)\n",
    "display(patlocations.head(5))\n",
    "\n",
    "reset_output()\n",
    "plot = GMapPlot(\n",
    "    x_range=Range1d(), y_range=Range1d(), \n",
    "    map_options=GMapOptions(lat=40, lng=-83, map_type=\"roadmap\", zoom=6)\n",
    ")\n",
    "plot.title.text = \"Patient Locations\"\n",
    "\n",
    "# For GMaps to function, Google requires you obtain and enable an API key:\n",
    "#\n",
    "#     https://developers.google.com/maps/documentation/javascript/get-api-key\n",
    "#\n",
    "# Replace the value below with your personal API key:\n",
    "plot.api_key = \"AIzaSyCfADVk_rJUwvypVHvSQZN8-TFr8jnvLmE\"\n",
    "\n",
    "circle = Circle(x=\"lng\", y=\"lat\", size=15, fill_color=\"green\", fill_alpha=1.0, line_color=None)\n",
    "src=ColumnDataSource(patlocations)\n",
    "plot.add_glyph(src, circle)\n",
    "\n",
    "plot.add_tools(PanTool(), WheelZoomTool())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_KZzgMX_uM_w"
   },
   "outputs": [],
   "source": [
    "# Now lets show the plot, which is interactive\n",
    "output_notebook()\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jcWzDEYCuM_y"
   },
   "source": [
    "### Show where the patients that overdosed live\n",
    "\n",
    "We can use color to highlight patients in different categories.  For example, we can show the patients that overdosed in red to see if there is a pattern to where they live."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yLsx-w09uM_y"
   },
   "outputs": [],
   "source": [
    "# Add 2 new columns to the DataFrame to indicate which patients overdosed and what color should be displayed\n",
    "patlocations['overdosed'] = np.where(patlocations['pat_id'].isin(patients_that_overdosed), 1, 0)\n",
    "patlocations['color'] = np.where(patlocations['overdosed'], 'red', 'green')\n",
    "\n",
    "display(patlocations[patlocations['overdosed'] == 1].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8a6luCFvuM_0"
   },
   "outputs": [],
   "source": [
    "# Display the graph\n",
    "reset_output()\n",
    "\n",
    "plot2 = GMapPlot(\n",
    "    x_range=Range1d(), y_range=Range1d(), \n",
    "    map_options=GMapOptions(lat=40, lng=-83, map_type=\"roadmap\", zoom=6)\n",
    ")\n",
    "plot2.title.text = \"Patient Locations (Overdose)\"\n",
    "plot2.api_key = \"AIzaSyCfADVk_rJUwvypVHvSQZN8-TFr8jnvLmE\"\n",
    "circle = Circle(x=\"lng\", y=\"lat\", size=15, fill_color=\"color\", fill_alpha=1.0, line_color=None)\n",
    "src=ColumnDataSource(patlocations)\n",
    "plot2.add_glyph(src, circle)\n",
    "\n",
    "plot2.add_tools(PanTool(), WheelZoomTool())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ijrhdC_9uM_2"
   },
   "outputs": [],
   "source": [
    "# Now show the graph\n",
    "output_notebook()\n",
    "show(plot2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hFb1Cm_3uM_4"
   },
   "source": [
    "## References and Further Reading\n",
    "\n",
    "- [`scikit-learn` user's guide](http://scikit-learn.org/stable/user_guide.html)\n",
    "- Vanderplas, J. (2016) [Python Data Science Handbook: Essential Tools for Working with Data](http://shop.oreilly.com/product/0636920034919.do). O'Reilly Media.\n",
    "- Much of this content can be attributed to the work of Chris Fonnesbeck with source data found at: https://github.com/fonnesbeck/Bios8366"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lgz3MpkpuM_5"
   },
   "source": [
    "# Continue to Modeling Techniques\n",
    "\n",
    "You have now properly extracted, cleaned, prepared and explored the data.  The next Jupyter notebook will walk through building and evaluating models from the data."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "NKBDS_Track1_Data_Prep.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
